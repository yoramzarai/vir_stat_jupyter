{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UR Clustering - scratch pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "\n",
    "from Bio import SeqIO\n",
    "from Bio.Cluster import kcluster\n",
    "\n",
    "\n",
    "file = 'ur.fasta'\n",
    "ur = [record.id for record in SeqIO.parse(file, 'fasta')]\n",
    "print(ur)\n",
    "\n",
    "# clustering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\n",
       "This is a latex cell. You can define $\\lambda_i$, for all $i\\in\\{0,\\dots,n\\}$ and\n",
       "\\[\n",
       "a = \\frac{m}{k}.    \n",
       "\\]\n",
       "and\n",
       "\\begin{equation}\n",
       "\\dot{x} = q_{i-1}(x) - q_i(x), \\quad \\text{for all } i=1,\\dots,n.\n",
       "\\label{eq:sample}\n",
       "\\end{equation}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\n",
    "This is a latex cell. You can define $\\lambda_i$, for all $i\\in\\{0,\\dots,n\\}$ and\n",
    "\\[\n",
    "a = \\frac{m}{k}.    \n",
    "\\]\n",
    "and\n",
    "\\begin{equation}\n",
    "\\dot{x} = q_{i-1}(x) - q_i(x), \\quad \\text{for all } i=1,\\dots,n.\n",
    "\\label{eq:sample}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Purpose Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS WAS COPIED INTO THE FILE mysequtils.py !!\n",
    "\n",
    "from Bio import SeqIO\n",
    "def my_fasta_read(fname):\n",
    "    '''Reads fasta file. \n",
    "    The functions returns a list of the sequences, a list of the sequences IDs \n",
    "    and a list of the sequences descriptions (content of the text following >>)'''\n",
    "    seq = []\n",
    "    iD = []\n",
    "    desc = []  # description \n",
    "    for record in SeqIO.parse(fname, \"fasta\"):\n",
    "        desc.append(record.description)\n",
    "        seq.append(str(record.seq))\n",
    "        iD.append(record.id)\n",
    "    return seq, iD, desc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for nucleotide clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting myseqclusters.py\n"
     ]
    }
   ],
   "source": [
    "#%%writefile myseqclusters.py\n",
    "import itertools as itr\n",
    "import csv\n",
    "\n",
    "def NT_base_seq_score(two_seqs, eql=+5, neql=-4):\n",
    "    '''Returns the score of the distance between two sequences. Default scorings are nuc44-based.'''\n",
    "    return(sum([eql if s1==s2 else neql for s1,s2 in zip(two_seqs[0], two_seqs[1])]))\n",
    "\n",
    "\n",
    "def NT_pair_seqs_score(all_seqs, score_func, eql=+5, neql=-4):\n",
    "    '''Returns a dictionary where the keys are all possible unique pairs of all_seqs, and the values are\n",
    "    the corresponding scores based on score_func'''\n",
    "    scores = {}\n",
    "    for a in itr.combinations(range(len(all_seqs)), 2):\n",
    "        #scores[all_seqs[a[0]]+'~'+all_seqs[a[1]]] = score_func((all_seqs[a[0]], all_seqs[a[1]]), eql, neql)\n",
    "        scores[(all_seqs[a[0]], all_seqs[a[1]])] = score_func((all_seqs[a[0]], all_seqs[a[1]]), eql, neql)\n",
    "    return scores\n",
    "\n",
    "\n",
    "def parse_starcode_cls_out(file):\n",
    "    '''This function parses the output of the tool starcode that \n",
    "    is used to cluster nucleotide sequences. The returned dictionary contains\n",
    "    a centroid as a key and a list of the correponding sequences in that\n",
    "    cluster as a value.'''\n",
    "    with open(file, 'rt') as fin:\n",
    "        clusts = [r[0].split('\\t') for r in csv.reader(fin, delimiter=' ')]\n",
    "\n",
    "    clusters = {}\n",
    "    for info in clusts: clusters[info[0]] = info[-1].split(',')\n",
    "    return clusters\n",
    "\n",
    "def parse_meshclsut_cls_out(file):\n",
    "    '''This function parses the output of the tool Meshclust that \n",
    "    is used to cluster nucleotide sequences. The returned dictionary contains\n",
    "    a centroid as a key and a list of the correponding sequences in that\n",
    "    cluster as a value.'''\n",
    "    clusters = {}\n",
    "    with open(file, 'rt') as fin:\n",
    "        for line in fin:\n",
    "            vals = line.split(' ')\n",
    "            if vals[0]=='>Cluster': # a new cluster\n",
    "                clst_num = int(vals[-1][0])\n",
    "                if clst_num > 0: # save the previous cluster\n",
    "                    clusters[centroid]=clst_seqs\n",
    "                clst_seqs = []\n",
    "                centroid = None\n",
    "            else:\n",
    "                seq = re.search('(\\w+)', vals[2]).group(0)\n",
    "                clst_seqs.append(seq)\n",
    "                if(vals[-1][0]=='*'):\n",
    "                    centroid=seq\n",
    "        # save the last cluster\n",
    "        clusters[centroid]=clst_seqs\n",
    "    return clusters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Testing the functions above'''\n",
    "\n",
    "from pprint import pprint\n",
    "import mysequtils as myut\n",
    "\n",
    "#A = ('CTGC', 'ATGG')\n",
    "#print('base score of {}:{} is {}'.format(A[0], A[1], NT_base_seq_score(A)))\n",
    "\n",
    "\n",
    "import itertools as itr\n",
    "#all_seqs = ('ATGC', 'ATTG', 'ACGT', 'ATGG')\n",
    "#all_scores=NT_pair_seqs_score(all_seqs, NT_base_seq_score)\n",
    "#pprint(all_scores)\n",
    "\n",
    "\n",
    "from Bio import SeqIO\n",
    "ur_file = 'ur.fasta'\n",
    "ur1_file = 'ur1.fasta'\n",
    "\n",
    "seq, iD, desc = my_fasta_read(ur1_file)\n",
    "#for i, s, d in zip(iD, seq, desc):\n",
    "#    print('id:{}, desc:{}, seq:{}'.format(i,d, s))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#urs = [x.id for x in list(SeqIO.parse(ur_file, \"fasta\"))]\n",
    "urs,_,_ = my_fasta_read(ur_file)\n",
    "#print(urs)\n",
    "#urs_scores=NT_pair_seqs_score(urs, NT_base_seq_score, 1, -1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# this is the UR set of vtaxid=1090134\n",
    "myur = { 'TCA', 'TGT', 'AGT', 'TTT', 'GAG', 'CAA', 'CTC', 'GAC' }\n",
    "urs_scores=NT_pair_seqs_score(list(myur), NT_base_seq_score, 1, -1)\n",
    "#pprint(urs_scores)\n",
    "\n",
    "from operator import itemgetter\n",
    "aa = sorted(urs_scores.items(), key=itemgetter(1), reverse=True)\n",
    "#print(aa)\n",
    "bb = sorted(aa, key=lambda entry: entry[0][0])\n",
    "#bb = sorted(urs_scores.items(), key=lambda entry: entry[0][0])\n",
    "\n",
    "for a in bb:\n",
    "    print('{}:{}'.format(a[0], a[1]))\n",
    "    \n",
    "# saving ur in a fasta file\n",
    "fasta_name = './ur2.fasta'\n",
    "with open(fasta_name, 'wt') as fout:\n",
    "    print(myut.seq_create_fasta(myur,myur), file=fout)\n",
    "print('file saved in ', fasta_name)\n",
    "\n",
    "\n",
    "# this is the UR set of vtaxid=1605721\n",
    "myur3 = {'GGAG', 'GCTT', 'AAGC', 'TCAG', 'CGGA', 'CTGA', 'AACG', 'GTTC', \\\n",
    " 'ACGT', 'AGCT', 'TCCG', 'AGCC', 'CTTC', 'GTTA', 'GGGG', 'GAAG', \\\n",
    " 'CGTT', 'CTCC', 'CCCC', 'CTTA', 'TTCG', 'GGAA', 'GGGA'}\n",
    "# saving ur in a fasta file\n",
    "fasta_name = './ur3.fasta'\n",
    "with open(fasta_name, 'wt') as fout:\n",
    "    print(myut.seq_create_fasta(myur3,myur3), file=fout)\n",
    "print('file saved in ', fasta_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse the output of starcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from pprint import pprint\n",
    "\n",
    "infile = 'ur2.fasta'\n",
    "file = 'ur_clust'  # startcode output\n",
    "\n",
    "ur_seq, _, _ = my_fasta_read(infile)\n",
    "\n",
    "with open(file, 'rt') as fin:\n",
    "    cin = csv.reader(fin, delimiter=' ')\n",
    "    clusts = [r for r in cin]\n",
    "\n",
    "print('urs = {}'.format(ur_seq))\n",
    "print('Found {} clusters:'.format(len(clusts)))\n",
    "for x in clusts:\n",
    "    info = x[0].split('\\t')\n",
    "    #print('centroid={}, members={}'.format(info[0], info[-1]))\n",
    "    print('{}:{}'.format(info[0], info[-1].split(',')))\n",
    "\n",
    "    \n",
    "clusters = parse_starcode_cls_out(file)\n",
    "pprint(clusters)\n",
    "\n",
    "\n",
    "file3 = 'ur3_clust'  # startcode output\n",
    "clusters3 = parse_starcode_cls_out(file3)\n",
    "pprint(clusters3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Starcode. \n",
    "\n",
    "This is an example of clustering a list of UR sequences using starcode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running:  ~/work/mystuff/tools/starcode/starcode -s --print-clusters -i ur4.seq -o ur4_clust\n",
      "{'AATT': ['AATT', 'AAAT', 'AAAA', 'GATC'],\n",
      " 'CGCG': ['CGCG'],\n",
      " 'GCCA': ['GCCA', 'CCCA', 'GCGC', 'GTCT'],\n",
      " 'TCAG': ['TCAG', 'CCAG'],\n",
      " 'TTTC': ['TTTC', 'TTTT']}\n",
      "Found 5 clusters:\n",
      "['AATT', 'AAAT', 'AAAA', 'GATC']\n",
      "['GCCA', 'CCCA', 'GCGC', 'GTCT']\n",
      "['TCAG', 'CCAG']\n",
      "['TTTC', 'TTTT']\n",
      "['CGCG']\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "import mysequtils as myut\n",
    "import subprocess\n",
    "\n",
    "\n",
    "str_exe = '~/work/mystuff/tools/starcode/starcode'\n",
    "#str_flags = ' -r 1 --print-clusters'   # message-passing algorithm\n",
    "str_flags = ' -s --print-clusters'   # sphere algorithm\n",
    "\n",
    "base_command = str_exe + str_flags\n",
    "\n",
    "# vtaxid = 458639\n",
    "myur4 = {'TTTC', 'CCAG', 'TTTT', 'AATT', 'GCCA', 'CCCA', \\\n",
    "         'AAAT', 'GATC', 'CGCG', 'GCGC', 'AAAA', 'GTCT', 'TCAG'}\n",
    "\n",
    "# vtaxid = 445686\n",
    "#myur4 = {'GGCT', 'AGCC', 'GCTA', 'GCTT', 'TTTT', 'AATT', \\\n",
    "#         'AAAT', 'CGCG', 'AAAA', 'GTCC', 'GGCC', 'CCGG', 'GTAC'}\n",
    "#infile = 'ur4.fasta'\n",
    "infile = 'ur4.seq'\n",
    "outfile = 'ur4_clust'\n",
    "\n",
    "\n",
    "command =  base_command + ' -i ' + infile  + ' -o ' + outfile\n",
    "\n",
    "# generate a fasta file containing the \n",
    "#with open(infile, 'wt') as fout:\n",
    "#    print(myut.seq_create_fasta(myur4,myur4), file=fout)\n",
    "# generate a file containing the sequences (a sequence per line)\n",
    "myut.seq2plain_text_file(myur4, infile)\n",
    "    \n",
    "# run starcode\n",
    "print('running: ', command)\n",
    "ret, stdout = subprocess.getstatusoutput(command) #os.system(command)\n",
    "\n",
    "if ret == 0:\n",
    "    # parse starcode output\n",
    "    clusters = parse_starcode_cls_out(outfile)\n",
    "    pprint(clusters)\n",
    "    print('Found {} clusters:'.format(len(clusters)))\n",
    "    for k in clusters.keys(): print(clusters[k])\n",
    "    \n",
    "else:\n",
    "    print('starcode errored and returned: ', stdout)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scratch pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('a1', 11):21\n",
      "('a2', 12):22\n",
      "('a3', 13):23\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'a_b_v'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "aa = OrderedDict()\n",
    "\n",
    "aa[('a1', 11)] = 21\n",
    "aa[('a2', 12)] = 22\n",
    "aa[('a3', 13)] = 23\n",
    "\n",
    "for k in aa.keys(): print('{}:{}'.format(k, aa[k]))\n",
    "    \n",
    "    \n",
    "'_'.join(['a', 'b', 'v'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Meshclust to cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 clusters:\n",
      "AATTG:['AATTG', 'ATTTT', 'AAATT', 'ACGTG', 'AATTC', 'TTTTT', 'AGCTT', 'TTTTC', 'TTTCA']\n",
      "AGCCA:['AGCCA', 'AGGCT', 'AGCCT', 'AGCTC', 'AGGCC', 'GGCTA', 'AGCTA', 'GGCTT', 'TGGCT', 'AAGCT', 'GAGCT', 'CAGCT', 'AAAAT', 'GGCTG', 'GGCTC']\n",
      "ACCGG:['ACCGG', 'GCTGG']\n",
      "AAAAA:['AAAAA']\n",
      "CAATT:['CAATT']\n",
      "\n",
      "Now using the function:\n",
      "Found 5 clusters:\n",
      "AATTG:['AATTG', 'ATTTT', 'AAATT', 'ACGTG', 'AATTC', 'TTTTT', 'AGCTT', 'TTTTC', 'TTTCA']\n",
      "AGCCA:['AGCCA', 'AGGCT', 'AGCCT', 'AGCTC', 'AGGCC', 'GGCTA', 'AGCTA', 'GGCTT', 'TGGCT', 'AAGCT', 'GAGCT', 'CAGCT', 'AAAAT', 'GGCTG', 'GGCTC']\n",
      "ACCGG:['ACCGG', 'GCTGG']\n",
      "AAAAA:['AAAAA']\n",
      "CAATT:['CAATT']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "# starcode parameters (we use Starcode to cluster)\n",
    "mesh_exe = '~/work/mystuff/tools/MeShClust-master/src/cluster/meshclust'\n",
    "mesh_flags = '--id 0.5'\n",
    "# ==========================================================================\n",
    "infile = 'ur.fasta'\n",
    "outfile = 'clst.mesh'\n",
    "\n",
    "mesh_flags = ' '.join([infile, mesh_flags, '--output '+outfile])\n",
    "command = mesh_exe + ' ' + mesh_flags\n",
    "#print(mesh_flags)\n",
    "ret, sout = subprocess.getstatusoutput(command)\n",
    "#print(ret, sout)\n",
    "\n",
    "# parse the output\n",
    "clusters = {}\n",
    "with open(outfile, 'rt') as fin:\n",
    "    for line in fin:\n",
    "        #print(line)\n",
    "        vals = line.split(' ')\n",
    "        #print(vals)\n",
    "        if vals[0]=='>Cluster':\n",
    "            clst_num = int(vals[-1][0])\n",
    "            if clst_num > 0: # save the previous cluster\n",
    "                clusters[centroid]=clst_seqs\n",
    "            # new cluster (ends previous cluster)\n",
    "            #print('A new cluster #{}'.format(clst_num))\n",
    "            clst_seqs = []\n",
    "            centroid = None\n",
    "        else:\n",
    "            seq = re.search('(\\w+)', vals[2]).group(0)\n",
    "            clst_seqs.append(seq)\n",
    "            #print('\\t',seq)\n",
    "            if(vals[-1][0]=='*'):\n",
    "                #print('\\tthis is the centroid')\n",
    "                centroid=seq\n",
    "    # save the last cluster\n",
    "    clusters[centroid]=clst_seqs\n",
    "\n",
    "print('Found {} clusters:'.format(len(clusters)))\n",
    "for k,v in clusters.items(): print('{}:{}'.format(k,v))\n",
    "    \n",
    "    \n",
    "clusters_f = parse_meshclsut_cls_out(outfile)    \n",
    "print('\\nNow using the function:')\n",
    "print('Found {} clusters:'.format(len(clusters_f)))\n",
    "for k,v in clusters_f.items(): print('{}:{}'.format(k,v))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
