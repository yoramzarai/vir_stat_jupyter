{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UR Correspondence between Hosts and Viruses\n",
    "\n",
    "Here we analyze the UR correspondance between hosts and viruses. The analyzed spreadsheet is \n",
    "cross_UR_m[val]_[rnd model].xlsx.\n",
    "\n",
    "## Parsing the correspondance xlsx files\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import pandas as pd\n",
    "import os, sys\n",
    "import re\n",
    "import myseq_logo as mysl\n",
    "import pald_funcs as mypal # my palindrome functions\n",
    "import mysequtils as myut\n",
    "from Bio import motifs, SeqIO\n",
    "from Bio.Seq import Seq\n",
    "import matplotlib.pyplot as plt\n",
    "import UR_host_funcs as urh\n",
    "from pprint import pprint\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "# MOVE These 2  TO UTILITIES FUNCTIONS\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def analyze_correp_URs(df, htypes, vtypes, ctypes, mlen, cross_d, ctype_pre = 'UR_'):\n",
    "    '''This function analyzes the UR correspondance between hosts and their\n",
    "    related viruses for a given m length.\n",
    "    In the input dictionary cross_d (to be updated and returned):\n",
    "    1. The keys are \"m:h:v:c:n\", where\n",
    "    m is the UR length, h is the host domain, v is the virus group, c is the \n",
    "    correspondance type (v_h, v_nh, or nv_h) and n is\n",
    "    the total number of URs found.\n",
    "    2. The values are a dictionary where the keys are the URs and the values are the\n",
    "    corresponding number of occurances found.\n",
    "    The input cross_d can be an empty dictionary, that will be updated by the function and returned.'''\n",
    "    for htype in htypes:\n",
    "        df_type = myut.my_filter_df(df, 'hst_db', htype)\n",
    "        for vtype in vtypes:\n",
    "            df_type2 = myut.my_filter_df(df_type, 'vrs_type', vtype)\n",
    "            #print(df_type2.head)\n",
    "            for ctype in ctypes:\n",
    "                ur = df_type2.loc[:,ctype_pre+ctype].apply(lambda x: x.split('|'))\n",
    "                allurs = [x for i in ur for x in i if x!='nan']\n",
    "                d_allurs = myut.get_seq_count(allurs) if allurs else {}\n",
    "                cross_d[':'.join([str(mlen), htype, vtype, ctype, str(ur.size)])] = d_allurs\n",
    "                if d_allurs:\n",
    "                    srt_allurs = sorted(d_allurs, key=d_allurs.get, reverse=True)\n",
    "    return cross_d, srt_allurs\n",
    "    \n",
    "# ------------------------------------------------------------------------------------------------------\n",
    "\n",
    "mlens = [3, 4, 5]\n",
    "\n",
    "vtypes = ('ssDNA', 'dsDNA', 'ssRNA', 'dsRNA', 'Retro-transcribing')\n",
    "htypes = ('Vertebrate', 'Bacteria', 'Fungi', 'Metazoa', 'Plants', 'Protists')\n",
    "ctypes = ('v_h', 'v_nh', 'nv_h')\n",
    "# =====================================================================================================\n",
    "base_path = '/Users/yoramzarai/work/school/Simulation/Viruses/Data_stats/'\n",
    "dtype_rnd = {'hst_db':str, 'hst_name':str, 'hst_taxid':int, 'vrs_taxid':int, \\\n",
    "             'vrs_type':str, 'UR_v_h':str, 'UR_v_nh':str, 'UR_nv_h':str, 'UR_nv_nh':str}\n",
    "mmlens = ['m'+str(m) for m in mlens]\n",
    "\n",
    "\n",
    "cross_d = defaultdict()\n",
    "for j, mlen in enumerate(mlens):\n",
    "    rnd_model = 'dnt_samp' if mlen==3 else 'syn_perm+dnt_samp'\n",
    "    # VUR xslx file\n",
    "    xlsx_file = os.path.join(base_path, 'cross_UR_'+mmlens[j]+'_'+rnd_model+'.xlsx')\n",
    "    df_cross = pd.read_excel(xlsx_file, header=0, dtype=dtype_rnd)\n",
    "    \n",
    "    # host-virus correspondance\n",
    "    cross_d, srt_allurs = analyze_correp_URs(df_cross, htypes, vtypes, ctypes, mmlens[j], cross_d)\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing the correspondance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAKE SURE THE CELL ABOVE RUNS FIRST !!\n",
    "\n",
    "# thresholds to show\n",
    "num_thres = 1 #11    # minimum number of entries in each group (set to 0 to show all)\n",
    "ratio_thres = 0.1 #0.5 # minimum ratio of seq occurance in group (set to 0 to show all)\n",
    "corsp_grp = {'nv_h', 'nv_h', 'nv_h'} # correspondance groups to analyze (all is ['v_h', 'v_nh', 'nv_h'])\n",
    "# ======================================================================================================\n",
    "print('Total of {} entries'.format(len(cross_d)))\n",
    "for k, v in cross_d.items():\n",
    "    srt = sorted(v, key=v.get, reverse=True)\n",
    "    mm, hh, vv, cc, nn = tuple(k.split(':'))\n",
    "    # printing a subset\n",
    "    if cc in corsp_grp:\n",
    "        print(mm, hh, vv, cc, nn, sep=',', end=':\\n')\n",
    "        for x in srt: \n",
    "            if v[x]/float(nn) >= ratio_thres and float(nn) >= num_thres:\n",
    "                print('\\t{}: {} ({:2.1f}%)'.format(x, v[x], v[x]/float(nn)*100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unique Correspondance (unique URs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THE FIRST CELL FIRST\n",
    "\n",
    "qmlens = [4, 5]  # 4 and/or 5 are the only options\n",
    "# ====================================================================================================\n",
    "base_q_file = '/Users/yoramzarai/work/school/Simulation/Viruses/Data_stats/cross_UR_uq_m'\n",
    "dtype_uq_rnd = {'hst_db':str, 'hst_name':str, 'hst_taxid':int, 'vrs_taxid':int, \\\n",
    "             'vrs_type':str, 'URq_v_h':str, 'URq_v_nh':str, 'URq_nv_h':str}\n",
    "\n",
    "cross_uq_d = defaultdict()\n",
    "for mlen in qmlens:\n",
    "    df_uq_cross = pd.read_excel(base_q_file+str(mlen)+'.xlsx', header=0, dtype=dtype_uq_rnd)\n",
    "    # host-virus correspondance\n",
    "    cross_uq_d, srt_uq_allurs = analyze_correp_URs(df_uq_cross, htypes, vtypes, ctypes, mlen, cross_uq_d, 'URq_')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing the unique correspondance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAKE SURE THE CELL ABOVE RUNS FIRST\n",
    "\n",
    "# thresholds to show\n",
    "num_uq_thres = 11 #11    # minimum number of entries in each group (set to 0 to show all)\n",
    "ratio_uq_thres = 0.03 #0.5 # minimum ratio of seq occurance in group (set to 0 to show all)\n",
    "corsp_uq_grp = {'nv_h', 'nv_h', 'nv_h'} # correspondance groups to analyze (all is ['v_h', 'v_nh', 'nv_h'])\n",
    "# =========================================================================================================\n",
    "print('Total of {} entries'.format(len(cross_uq_d)))\n",
    "for k, v in cross_uq_d.items():\n",
    "    srt = sorted(v, key=v.get, reverse=True)\n",
    "    qmm, qhh, qvv, qcc, qnn = tuple(k.split(':'))\n",
    "    # printing a subset\n",
    "    if qcc in corsp_uq_grp:\n",
    "        print(qmm, qhh, qvv, qcc, qnn, sep=',', end=':\\n')\n",
    "        for x in srt: \n",
    "            if v[x]/float(qnn) >= ratio_uq_thres and float(qnn) >= num_uq_thres:\n",
    "                print('\\t{}: {} ({:2.1f}%)'.format(x, v[x], v[x]/float(qnn)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch Pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "htype_tmp = 'Bacteria'\n",
    "vtype_tmp = 'dsRNA'\n",
    "ctype_tmp = 'nv_h'\n",
    "\n",
    "cross_d_tmp = defaultdict()\n",
    "\n",
    "df_tmp1 = myut.my_filter_df(df_cross, 'hst_db', htype_tmp)\n",
    "df_tmp2 = myut.my_filter_df(df_tmp1, 'vrs_type', vtype_tmp)\n",
    "#print(df_tmp2)\n",
    "ur_tmp = df_tmp2.loc[:,'UR_'+ctype_tmp].apply(lambda x: x.split('|'))\n",
    "allurs_tmp = [x for i in ur_tmp for x in i if x!='nan']\n",
    "d_allurs_tmp = myut.get_seq_count(allurs_tmp) if allurs_tmp else {}\n",
    "#print(allurs_tmp)\n",
    "pprint(d_allurs_tmp)\n",
    "cross_d_tmp[':'.join([str(4), htype_tmp, vtype_tmp, ctype_tmp, str(ur_tmp.size)])] = d_allurs_tmp\n",
    "pprint(cross_d_tmp)\n",
    "\n",
    "#ur = df_type.loc[:,'UR_nv_h'].apply(lambda x:x.split('|'))\n",
    "#print(ur.iloc[0])\n",
    "#allurs = [x for i in ur for x in i if x!='nan']\n",
    "#print(ur.index[0])\n",
    "#print(allurs, len(allurs), ur.shape[0], len(allurs)/ur.size)\n",
    "    \n",
    "#xx = ['AAA', 'AAB', 'AAC', 'AAA', 'AAA', 'AAB', 'KKK', 'AAA', 'KKK']\n",
    "#pprint(myut.get_seq_count(xx))\n",
    "    \n",
    "#ss = ':'.join(['a', 'b', 'c'])\n",
    "#print(ss)\n",
    "\n",
    "#print(my_filter_df(df_type2, 'hst_db', 'Protists'))\n",
    "#print(my_filter_df(df_type2, 'hst_db', 'Protists', ['hst_name', 'hst_taxid', 'vrs_taxid', 'UR_nv_h']))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
